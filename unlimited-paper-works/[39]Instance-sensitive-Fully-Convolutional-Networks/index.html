<!doctype html>
<html class="docs-version-current" lang="zh-cn" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.9">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.20/dist/katex.min.css" crossorigin="anonymous"><title data-react-helmet="true">Instance-sensitive Fully Convolutional Networks | 工具箱的深度学习记事簿</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://ml.akasaki.space//unlimited-paper-works/[39]Instance-sensitive-Fully-Convolutional-Networks"><meta data-react-helmet="true" name="docusaurus_locale" content="zh-cn"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-docs-current"><meta data-react-helmet="true" property="og:title" content="Instance-sensitive Fully Convolutional Networks | 工具箱的深度学习记事簿"><meta data-react-helmet="true" name="description" content="Jifeng Dai, Kaiming He, Yi Li, Shaoqing Ren, Jian Sun"><meta data-react-helmet="true" property="og:description" content="Jifeng Dai, Kaiming He, Yi Li, Shaoqing Ren, Jian Sun"><link data-react-helmet="true" rel="shortcut icon" href="/img/logo.svg"><link data-react-helmet="true" rel="canonical" href="https://ml.akasaki.space//unlimited-paper-works/[39]Instance-sensitive-Fully-Convolutional-Networks"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//unlimited-paper-works/[39]Instance-sensitive-Fully-Convolutional-Networks" hreflang="zh-cn"><link data-react-helmet="true" rel="alternate" href="https://ml.akasaki.space//unlimited-paper-works/[39]Instance-sensitive-Fully-Convolutional-Networks" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.54fd31ab.css">
<link rel="preload" href="/assets/js/runtime~main.e23c63c0.js" as="script">
<link rel="preload" href="/assets/js/main.f6709b37.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div><a href="#" class="skipToContent_OuoZ">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--light_4Vu1"><img src="/img/logo.svg" alt="Logo" class="themedImage_TMUO themedImage--dark_uzRr"></div><b class="navbar__title">工具箱的深度学习记事簿</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/unlimited-paper-works/">魔法部日志</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/neet-cv/ml.akasaki.space" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_wgqa"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_iYfV toggle_2i4l toggleDisabled_xj38"><div class="toggleTrack_t-f2" role="button" tabindex="-1"><div class="toggleTrackCheck_mk7D"><span class="toggleIcon_pHJ9">🌜</span></div><div class="toggleTrackX_dm8H"><span class="toggleIcon_pHJ9">🌞</span></div><div class="toggleTrackThumb_W6To"></div></div><input type="checkbox" class="toggleScreenReader_h9qa" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_lDyR"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_i9tI" type="button"></button><aside class="docSidebarContainer_0YBq"><div class="sidebar_a3j0"><nav class="menu thin-scrollbar menu_cyFh"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/">工具箱的深度学习记事簿</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><a class="menu__link menuLinkText_OKON">魔法部日志（又名论文阅读日志）</a><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/">欢迎来到魔法部日志</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[01]The-Devil-is-in-the-Decoder-Classification-Regression-and-GANs">The Devil is in the Decoder: Classification, Regression and GANs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[02]Threat-of-Adversarial-Attacks-on-Deep-Learning-in-Computer-Vision-A-Survey">Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[03]Progressive-Semantic-Segmentation">Progressive Semantic Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[04]Decoders-Matter-for-Semantic-Segmentation-Data-Dependent-Decoding-Enables-Flexible-Feature-Aggregation">Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[05]HLA-Face-Joint-High-Low-Adaptation-for-Low-Light-Face-Detection">HLA-Face Joint High-Low Adaptation for Low Light Face Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[06]DeepLab-Series">DeepLab Series</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[07]Cross-Dataset-Collaborative-Learning-for-Semantic-Segmentation">Cross-Dataset Collaborative Learning for Semantic Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[08]Dynamic-Neural-Networks-A-Survey">Dynamic Neural Networks: A Survey</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[09]Feature-Pyramid-Networks-for-Object-Detection">Feature Pyramid Networks for Object Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[10]Overview-Of-Semantic-Segmentation">A Review on Deep Learning Techniques Applied to Semantic Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[11]Image-Segmentation-Using-Deep-Learning-A-Survey">Image Segmentation Using Deep Learning: A Survey</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[12]MobileNetV2-Inverted-Residuals-and-Linear-bottleneck">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[13]Fast-SCNN-Fast-Semantic-Segmentation-Network">Fast-SCNN: Fast Semantic Segmentation Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[14]MobileNets-Efficient-Convolutional-Neural-Networks-for-Mobile-Vision-Applications">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[15]Gated-Channel-Transformation-for-Visual-Recognition">Gated Channel Transformation for Visual Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[16]Convolutional-Block-Attention-Module">Convolutional Block Attention Module</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[17]Boundary-IoU-Improving-Object-Centri-Image-Segmentation-Evaluation">Boundary IoU: Improving Object-Centric Image Segmentation Evaluation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[18]Involution-Inverting-the-Inherence-of-Convolution-for-Visual-Recognition">Involution: Inverting the Inherence of Convolution for Visual Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[19]PointRend-Image-Segmentation-as-Rendering">PointRend: Image Segmentation as Rendering</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[20]Transformer-Attention-is-all-you-need">Transformer: Attention is all you need</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[21]RefineMask_Towards_High-Quality_Instance_Segmentationwith_Fine-Grained_Features">RefineMask: Towards High-Quality Instance Segmentationwith Fine-Grained Features</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[22]GLADNet-Low-Light-Enhancement-Network-with-Global-Awareness">GLADNet: Low-Light Enhancement Network with Global Awareness</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[23]Squeeze-and-Excitation-Networks">Squeeze-and-Excitation Networks (SENet)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[24]BiSeNet-Bilateral-Segmentation-Network-for-Real-time-Semantic-Segmentation">BiSeNet: Bilateral Segmentation Network for Real-time Semantic Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[25]Rethinking-BiSeNet-For-Real-time-Semantic-Segmentation">Rethinking BiSeNet For Real-time Semantic Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[26]CBAM-Convolutional-Block-Attention-Module">CBAM: Convolutional Block Attention Module</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[27]Non-local-Neural-Networks">Non-local Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[28]GCNet-Non-local-Networks-Meet-Squeeze-Excitation-Networks-and-Beyond">GCNet: Global Context Networks (Non-local Networks Meet Squeeze-Excitation Networks and Beyond)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[29]Disentangled-Non-Local-Neural-Networks">Disentangled Non-Local Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[30]RetinexNet-for-Low-Light-Enhancement">Deep Retinex Decomposition for Low-Light Enhancement</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[31]MSR-netLow-light-Image-Enhancement-Using-Deep-Convolutional-Network">MSR-net:Low-light Image Enhancement Using Deep Convolutional Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[32]LLCNN-A-Convolutional-Neural-Network-for-Low-light-Image-Enhancement">LLCNN: A convolutional neural network for low-light image enhancement</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[33]VOLO-Vision-Outlooker-for-Visual-Recognition">VOLO: Vision Outlooker for Visual Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[34]Polarized-Self-Attention-Towards-High-quality-Pixel-wise-Regression">Polarized Self-Attention: Towards High-quality Pixel-wise Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[35]SimAM-A-Simple-Parameter-Free-Attention-Module-for-Convolutional-Neural-Networks">SimAM: A Simple, Parameter-Free Attention Module for Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[36]SOLO-Segmenting-Objects-by-Locations">SOLO: Segmenting Objects by Locations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[37]YOLACT-Real-time-Instance-Segmentation">YOLACT: Real-time Instance Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[38]You-Only-Look-One-level-Feature">You Only Look One-level Feature</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/unlimited-paper-works/[39]Instance-sensitive-Fully-Convolutional-Networks">Instance-sensitive Fully Convolutional Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[40]Learning-in-the-Frequency-Domain">Learning in the Frequency Domain</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[41]Generative-Adversarial-Networks">Generative Adversarial Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation">[42]CCNet-Criss-Cross-Attention-for-Semantic-Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[43]RepVGG-Making-VGG-style-ConvNets-Great-Again">[43]RepVGG-Making-VGG-style-ConvNets-Great-Again</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network">[44]PP-LCNet-A-Lightweight-CPU-Convolutional-Neural-Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows">[45]Swin-Transformer-Hierarchical-Vision-Transformer-using-Shifted-Windows</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/unlimited-paper-works/[46]Demystifying-Local-Vision-Transformer">[46]Demystifying-Local-Vision-Transformer</a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_eoK2"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_e+kA"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></aside><main class="docMainContainer_r8cw"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_zHA2"><div class="docItemContainer_oiyr"><article><div class="tocCollapsible_aw-L theme-doc-toc-mobile tocMobile_Tx6Y"><button type="button" class="clean-btn tocCollapsibleButton_zr6a">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Instance-sensitive Fully Convolutional Networks</h1></header><p><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dai%2C+J" target="_blank" rel="noopener noreferrer">Jifeng Dai</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=He%2C+K" target="_blank" rel="noopener noreferrer">Kaiming He</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Li%2C+Y" target="_blank" rel="noopener noreferrer">Yi Li</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ren%2C+S" target="_blank" rel="noopener noreferrer">Shaoqing Ren</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sun%2C+J" target="_blank" rel="noopener noreferrer">Jian Sun</a></p><blockquote><p>Fully convolutional networks (FCNs) have been proven very successful for semantic segmentation, but the FCN outputs are unaware of object instances. In this paper, we develop FCNs that are capable of proposing instance-level segment candidates. In contrast to the previous FCN that generates one score map, our FCN is designed to compute a small set of instance-sensitive score maps, each of which is the outcome of a pixel-wise classifier of a relative position to instances. On top of these instance-sensitive score maps, a simple assembling module is able to output instance candidate at each position. In contrast to the recent DeepMask method for segmenting instances, our method does not have any high-dimensional layer related to the mask resolution, but instead exploits image local coherence for estimating instances. We present competitive results of instance segment proposal on both PASCAL VOC and MS COCO.</p></blockquote><p>这篇工作又名InstanceFCN。实例分割方面，由于网络难以同时进行分类和分割任务，因此首先流行的是二阶段实例分割网络，首先对输入找到实例的proposal，然后在其中进行密集预测（也就是先框框再分割）。本文从名称上看不是一篇讲实例分割的文章，是讲如何通过FCN获得实例级别的分割mask的的。</p><p>在阅读之前我想提醒一下，这篇工作的效果是比较差的，毕竟是早期工作。不过这篇工作具有不错的启发意义，值得读一读。后面的一篇工作FCIS（Fully Convolutional Instance-aware Semantic Segmentation）中就借鉴了本文中提出的instance-sensitive score maps（请不要弄混本篇工作和FCIS）。本文的一大贡献就是提出使用instance-sensitive score maps区分不同个体。</p><hr><h2 class="anchor anchorWithStickyNavbar_y2LR" id="instancefcn">InstanceFCN<a aria-hidden="true" class="hash-link" href="#instancefcn" title="Direct link to heading">​</a></h2><p>大家也称这篇工作为InstanceFCN。这篇工作的功能只是区分了实例，并没有区分类别。这是一篇”两不像“的工作。我们可以称之为”对象分割“：</p><table><thead><tr><th>名称</th><th>描述</th></tr></thead><tbody><tr><td>语义分割</td><td>区分各个像素类别的密集预测任务</td></tr><tr><td>实例分割</td><td>区分各个像素类别及其属于的对象实例的密集预测任务</td></tr><tr><td>对象分割（本篇工作）</td><td>区分各个像素属于的对象实例的密集预测任务</td></tr></tbody></table><p>这篇工作是使用全卷积网络区分像素所属的对象实例的：</p><p><img alt="image-20210831174047097" src="/assets/images/image-20210831174047097-474e8d3ba8294fe2a3d3fdaa51ae0c02.png"></p><p>上图是InstanceFCN的主要结构。可以看出，在特征提取网络之后（原论文中InstanceFCN使用在ImageNet上预训练的修改版VGG-16作为骨干特征提取网络，修改版是指作者对原版的VGG-16做了一些调整避免过度的下采样导致分辨率过度损失。具体可以看一下原论文中算法部分的相关描述），InstanceFCN在骨干特征提取网络之后主要分为两个分支，分别是instance分支（用于产生实例级的像素打分）以及objectness分支（用于产生某位置是不是一个实体的打分）。这两个分支的结果将相乘形成最终的得分。</p><p>接下来我们主要聊一下这两个分支如何工作。</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="instance分支">Instance分支<a aria-hidden="true" class="hash-link" href="#instance分支" title="Direct link to heading">​</a></h2><p>这个分支的作用产生一个像素与实体关系的打分，可衡量一个像素应该属于哪个实例。这个分支分为两个阶段：</p><ol><li>通过卷积得到instance-sensitive score maps。</li><li>一个assembling module将它们组装称为最终的结果。</li></ol><p>接下来分别介绍这两个阶段。</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="instance-sensitive-score-maps">Instance-sensitive score maps<a aria-hidden="true" class="hash-link" href="#instance-sensitive-score-maps" title="Direct link to heading">​</a></h3><p>instance-sensitive score maps是这份工作的核心贡献之一。InstanceFCN通过这一贡献实现区分不同对象。在语义分割模型中，通常将损失设定为交叉熵，因此每个像素在优化时仅表达一个语义。这对于很多个对象存在重叠的像素难以判断其所属。</p><p>相比于用于语义分割的FCN在最终输出一个类别，InstanceFCN最后的输出是一个像素于对象关系的打分。大致上去理解，就=就是一个像素越可能属于某个对象，这个打分就越高。进行打分的方式来源于一个简单的规则：不同对象应该处在不同位置。因此在原论文中，作者使用<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k\times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>的矩阵定义一种”相对位置“：</p><p><img alt="image-20210831165835721" src="/assets/images/image-20210831165835721-f66e3a7863a6cf5be594bd9944682e52.png"></p><p>例如在上图中，<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>，就会产生<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup><mo>=</mo><mn>9</mn></mrow><annotation encoding="application/x-tex">k^2=9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">9</span></span></span></span></span>个score map。这些score map被称为instance-sensitive score maps，可以用于对像素和对象的相对位置进行打分。</p><p>这个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k\times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>的矩阵我们暂且称之为”打分器“。这个打分器是一个在全图上移动的滑动窗口，将对全图的各个区域进行打分。还是刚才提到的，作者认为不同的对象处于不同的位置。所以只要打分器在所有位置都打一下分，使每个像素都具有一个跟位置相关的分数，就能区分这个像素到底属于哪个对象。例如上图中有两个类别为人的实体，打分器在左侧的人的位置产生的score maps最终仅拼接出了左侧的人，并没有拼接出右面的。</p><p>根据原论文，前置骨干特征提取网络输出特征图后，首先使用一个512-d的<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>卷积对特征进行一下转换，然后使用一个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>的卷积层产生instance-sensitive score maps：</p><p><img alt="image-20210831195822063" src="/assets/images/image-20210831195822063-071c09a168b1bef61d2ec4e248577b60.png"></p><p>刚才我们提到论文中使用一个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k\times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>的网格打分器描述某种相对位置信息，所以这个用于形成score map的<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>卷积层卷积核维度就是<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">k^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>。也就是对于输出，分辨率上每个像素后方堆叠着<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">k^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>个数字，分别表示这个像素对<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">k^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>个相对位置的打分。</p><p>这里可能会产生一个小疑问，就是卷积核明明是逐像素的迭代，而且根据上面的描述只有<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>的大小，怎么可能覆盖图中的区域：</p><p><img alt="image-20210831201633024" src="data:image/png;base64,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"></p><p>例如这幅示意图中，一个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi><mo separator="true">,</mo><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k\times k,k=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>的打分器命名就是一个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>的卷积核，如何覆盖一个人的像素范围？我自己的理解是VGG-16都进来卷过了，一个像素就已经能代表一定大小的感受野了。而且在<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>卷积之前还有一个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>的卷积层，训练过程它学了啥全是玄学。这就导致了这部分可解释性比较牵强（也许是我才疏学浅解读失误）。<code>大家都常讲起这个笑话：“通过学习的卷积核能做到的话解释不通也是能解释通的”。如果您有心钻研深度神经网络的可解释性，那么祝您能在这条路上走得顺利👻。有任何实质性的进展请让我也了解一下您的工作</code>。</p><blockquote><p>插一嘴，我在想这样的结构在不同感受野的物体上表现应该不会均衡吧。这样设计实属是把对不同感受野的兼容性抛给了骨干网络和那个不知道为什么存在的<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>卷积。看了一眼原论文试验结果部分，确实效果一般。会不会换上Res-Net或者U结构的网络后性能会显著提升呢？</p></blockquote><p>这样我们就得到了一份instance-sensitive score maps。不过仅凭此还不能区分出对象，还需要通过一个称为组装（assembling）的过程生成对象级的输出。</p><h3 class="anchor anchorWithStickyNavbar_y2LR" id="instance-assembling-module">Instance assembling module<a aria-hidden="true" class="hash-link" href="#instance-assembling-module" title="Direct link to heading">​</a></h3><p>instance-sensitive score maps还不足以直接产生对象实例。但是可以通过”组装“score maps来产生对象实例：</p><p><img alt="image-20210831180137018" src="/assets/images/image-20210831180137018-a9cbfa1c7a291f6bae17c3f500e76b46.png"></p><p>例如，在上图所示的两个类别为人的对象上，通过卷积打分产生instance-sensitive score maps。我们可以看出，当这个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi><mo separator="true">,</mo><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k\times k ,k=3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>的打分器位于左侧的人的位置时，在这个打分器内部的<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup><mo>=</mo><mn>9</mn></mrow><annotation encoding="application/x-tex">k^2 = 9</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">9</span></span></span></span></span>个位置上输出产生了不同的score map（也就是上个阶段网络的输出是<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">k^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>维的，分别代表当前位置下和这<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">k^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>个区域的相对位置关系分数）。</p><p>接下来Instance assembling module会用这个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>k</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">k^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>维的输出“组装”出一个像素级的实例输出。原论文将这个组装的模块描述为一个大小为<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>×</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">m\times m</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span></span></span></span></span>的窗口（其中m是k的倍数），将这个窗口分为<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>m</mi><mi>k</mi></mfrac><mo>×</mo><mfrac><mi>m</mi><mi>k</mi></mfrac></mrow><annotation encoding="application/x-tex">\frac{m}{k}\times \frac{m}{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0404em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1.0404em;vertical-align:-0.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6954em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em">k</span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">m</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span>个子窗口，也就是每个窗口是<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k\times k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal" style="margin-right:0.03148em">k</span></span></span></span></span>这么大，每个子窗口直接从score map的相应位置复制对应的值，然后拼在一起（依据它们的相对位置拼在一起）形成<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>m</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">m^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>大小的输出。在原文中，作者选择了<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>=</mo><mn>21</mn></mrow><annotation encoding="application/x-tex">m=21</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal">m</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">21</span></span></span></span></span>，步长<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mi>t</mi><mi>r</mi><mi>i</mi><mi>d</mi><mi>e</mi><mo>=</mo><mn>8</mn></mrow><annotation encoding="application/x-tex">stride = 8</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">8</span></span></span></span></span>。</p><p>作者在原文中重申，这个模块是没有参数的，其中仅包含复制粘贴的操作，不需要学习。但是这个模块仍然是产生<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>m</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">m^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>分辨率输出的“唯一指定组件”（the only component），是网络的重要组件，且特征图由它经手后得到的输出直接参与loss计算，所以其设计影响网络的训练优化过程。</p><blockquote><p>回看刚才我们在Instance-sensitive score maps那里提到的小疑问，InstanceFCN通过卷积产生“位置敏感的”输出仅通过卷积这件事确实难以解释。如果真的是这样，为什么不直接在组装部分也直接用一个可以学习的卷积解决呢？个人认为这个“复制粘贴”模块是解释的一部分。作者在重申的时候也提到了，这个模块影响网络的训练优化。也就是说，它是干预前序网络学习行为的。因为它“对着位置复制粘贴”的行为，在优化网络的时候导致了前面score map的产生是区域敏感的（以上纯属我自己的臆想）。</p></blockquote><p>由于这篇论文并没有提供具体的代码，所以这个assembling模块的具体设计无从知晓。猜测是一个<code>[0,0,...,1,...,0]</code>长相的卷积。</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="object分支">Object分支<a aria-hidden="true" class="hash-link" href="#object分支" title="Direct link to heading">​</a></h2><p>这个分支用于产生Objectness score map，主要用于判别某个位置存在一个实体的可能性。</p><p><img alt="image-20210902090944392" src="/assets/images/image-20210902090944392-db6d9ff107c0e2891fdd0132623a12c5.png"></p><p>如上图，这个分支和Instance分支是并行的。在原论文的描述中，该分支使用一个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">3\times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">3</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">3</span></span></span></span></span>卷积和一个<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>卷积构成。其中<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">1\times 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>卷积是一个密集（逐像素）的logistic回归，回归为两类，一类是“背景”，一类是“实体”。</p><p><img alt="image-20210831174047097" src="/assets/images/image-20210831174047097-474e8d3ba8294fe2a3d3fdaa51ae0c02.png"></p><p>接下来这两个分支产生的结果直接相乘得到最终结果。注意，object分支的输出分辨率要和instace分支匹配，否则没法按位相乘。</p><h2 class="anchor anchorWithStickyNavbar_y2LR" id="loss设计">Loss设计<a aria-hidden="true" class="hash-link" href="#loss设计" title="Direct link to heading">​</a></h2><div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>i</mi></munder><mo stretchy="false">(</mo><mi>L</mi><mo stretchy="false">(</mo><msub><mi>p</mi><mi>i</mi></msub><mo separator="true">,</mo><msubsup><mi>p</mi><mi>i</mi><mo>∗</mo></msubsup><mo stretchy="false">)</mo><mo>+</mo><munder><mo>∑</mo><mi>j</mi></munder><mi>L</mi><mo stretchy="false">(</mo><msub><mi>S</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow></msub><mo separator="true">,</mo><msubsup><mi>S</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>j</mi></mrow><mo>∗</mo></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sum_i (L(p_i,p_i^*)+\sum_j L(S_{i,j},S_{i,j}^*))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.3277em;vertical-align:-1.2777em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2777em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7387em"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:2.4638em;vertical-align:-1.4138em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8723em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4138em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">L</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">S</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.7387em"><span style="top:-2.453em;margin-left:-0.0576em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight" style="margin-right:0.05724em">j</span></span></span></span><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">∗</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3831em"><span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span></span></div><p>其中<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">p</span></span></span></span></span>的部分是在计算object分支的loss，<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>S</mi></mrow><annotation encoding="application/x-tex">S</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.05764em">S</span></span></span></span></span>的部分是在计算intance分支的loss。</p></div></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/unlimited-paper-works/[38]You-Only-Look-One-level-Feature"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">« <!-- -->You Only Look One-level Feature</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/unlimited-paper-works/[40]Learning-in-the-Frequency-Domain"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Learning in the Frequency Domain<!-- --> »</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_vrFS thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#instancefcn" class="table-of-contents__link toc-highlight">InstanceFCN</a></li><li><a href="#instance分支" class="table-of-contents__link toc-highlight">Instance分支</a><ul><li><a href="#instance-sensitive-score-maps" class="table-of-contents__link toc-highlight">Instance-sensitive score maps</a></li><li><a href="#instance-assembling-module" class="table-of-contents__link toc-highlight">Instance assembling module</a></li></ul></li><li><a href="#object分支" class="table-of-contents__link toc-highlight">Object分支</a></li><li><a href="#loss设计" class="table-of-contents__link toc-highlight">Loss设计</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container"><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2021 neet-cv. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.e23c63c0.js"></script>
<script src="/assets/js/main.f6709b37.js"></script>
</body>
</html>